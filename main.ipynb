{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import csv\n",
    "\n",
    "# Set up necessary directories and configurations:\n",
    "os.makedirs('data', exist_ok=True)\n",
    "session = requests.Session()\n",
    "retries = Retry(total=3, backoff_factor=1, status_forcelist=[500, 502, 503, 504])\n",
    "session.mount('http://', HTTPAdapter(max_retries=retries))\n",
    "session.mount('https://', HTTPAdapter(max_retries=retries))\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Clean title by standardizing the \"By H. P. Lovecraft\" text:\n",
    "def clean_title(title):\n",
    "    author_text = \"By H. P. Lovecraft\"\n",
    "    title = re.sub(rf\"({author_text}\\s*)+\", author_text, title).strip()\n",
    "    if title.endswith(author_text) and not title.endswith(\" \" + author_text):\n",
    "        title = title.replace(author_text, \" \" + author_text)\n",
    "    return title\n",
    "\n",
    "# --- Step 1: Scraping Lovecraft Fiction Works ---\n",
    "\n",
    "def scrape_lovecraft_content():\n",
    "    base_url = \"https://www.hplovecraft.com/writings/texts/\"\n",
    "    response = session.get(base_url)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to access the base URL: {response.status_code}\")\n",
    "        return\n",
    "    \n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    content_links = [\n",
    "        f\"{base_url}{link['href']}\"\n",
    "        for link in soup.find_all('a', href=True)\n",
    "        if link['href'].startswith('fiction/') and not link['href'].startswith('#')\n",
    "    ]\n",
    "\n",
    "    csv_filename = 'data/lovecraft_fiction.csv'\n",
    "    with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow(['Content Type', 'Title', 'Text'])\n",
    "\n",
    "        for content_url in content_links:\n",
    "            time.sleep(random.uniform(1, 3))\n",
    "            try:\n",
    "                content_response = session.get(content_url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "                if content_response.status_code == 200:\n",
    "                    content_soup = BeautifulSoup(content_response.content, 'html.parser')\n",
    "                    title_tag = content_soup.find('font', size=\"+2\")\n",
    "                    author_tag = content_soup.find('font', size=\"+1\")\n",
    "                    text_div = content_soup.find('div', align='justify')\n",
    "\n",
    "                    if title_tag and text_div:\n",
    "                        title = f\"{title_tag.get_text(strip=True)} by {author_tag.get_text(strip=True)}\"\n",
    "                        title = clean_title(title)  # Clean the title text\n",
    "                        csvwriter.writerow([\"fiction\", title, text_div.get_text(strip=True)])\n",
    "                        print(f'Scraped: {title}')\n",
    "                    else:\n",
    "                        print(f'Title or text not found for {content_url}')\n",
    "                else:\n",
    "                    print(f'Failed to scrape {content_url}: {content_response.status_code}')\n",
    "            except Exception as e:\n",
    "                print(f'Error scraping {content_url}: {e}')\n",
    "\n",
    "# Scrape only fiction content:\n",
    "scrape_lovecraft_content()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the scraped CSV data into a Pandas DataFrame\n",
    "df = pd.read_csv('data/lovecraft_fiction.csv')\n",
    "\n",
    "# View the first few rows of the dataframe to verify\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Ensure stopwords are downloaded\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Tokenize and remove stopwords\n",
    "def clean_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    cleaned_tokens = [word.lower() for word in tokens if word.isalnum() and word.lower() not in stop_words]\n",
    "    return \" \".join(cleaned_tokens)\n",
    "\n",
    "# Apply to the text column in the dataframe\n",
    "df['Cleaned_Text'] = df['Text'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Create a frequency distribution for words in all texts\n",
    "all_words = \" \".join(df['Cleaned_Text']).split()\n",
    "word_freq = Counter(all_words)\n",
    "\n",
    "# Display the most common words\n",
    "print(word_freq.most_common(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "# Create a word cloud from the cleaned text\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(\" \".join(df['Cleaned_Text']))\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from collections import Counter\n",
    "\n",
    "# Load the spaCy model for Named Entity Recognition\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Function to extract entities\n",
    "def extract_entities(text):\n",
    "    doc = nlp(text)\n",
    "    entities = [ent.text.lower() for ent in doc.ents if ent.label_ in ['PERSON', 'ORG', 'GPE', 'LOC']]\n",
    "    return entities\n",
    "\n",
    "# Apply the extraction to the 'Cleaned_Text' column\n",
    "df['Entities'] = df['Cleaned_Text'].apply(extract_entities)\n",
    "\n",
    "# Flatten the list of entities and get their frequency count\n",
    "all_entities = [entity for sublist in df['Entities'] for entity in sublist]\n",
    "entity_freq = Counter(all_entities)\n",
    "\n",
    "# Display the most common entities\n",
    "print(entity_freq.most_common(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom list of Lovecraft entities to track\n",
    "lovecraft_entities = [\n",
    "    \"cthulhu\", \"yog-sothoth\", \"nyarlathotep\", \"innsmouth\", \"arkham\", \"dunwich\", \"azathoth\", \"shub-niggurath\",\n",
    "    \"hastur\", \"miskatonic\", \"the king in yellow\", \"the dark young\", \"the colour out of space\", \"the great old ones\"\n",
    "]\n",
    "\n",
    "# Extract frequencies for these specific entities\n",
    "specific_entity_freq = {entity: all_entities.count(entity) for entity in lovecraft_entities}\n",
    "\n",
    "# Display the count of these specific entities\n",
    "print(specific_entity_freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Load the spaCy model for Named Entity Recognition\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Expanded list of Lovecraftian and related entities (including new ones)\n",
    "lovecraft_entities_expanded = [\n",
    "    \"cthulhu\", \"yog-sothoth\", \"nyarlathotep\", \"azathoth\", \"hastur\", \"r'lyeh\", \"dagon\", \n",
    "    \"shub-niggurath\", \"the great old ones\", \"elder gods\", \"the old ones\", \"the deep ones\", \"night gaunts\", \n",
    "    \"cthulhu cult\", \"the nameless city\", \"the black stone\", \"the dreamlands\", \"fenric\", \"hecuba\", \n",
    "    \"animus\", \"tor-gasukk\", \"moloch\", \"kai'lizakia\", \"lloigor\", \"eidolon\", \"derleth\", \"gog\", \"magog\", \"to'koth\", \n",
    "    \"karnas'koi\", \"traguam\", \"archon\", \"mi'en kalarash\", \"kwundaar\", \"volund\", \"k'thun\", \"noth-yidik\", \"tru'nembra\", \n",
    "    \"tulzscha\", \"cxaxukluth\", \"d'endrrah\", \"ubbo-sathla\", \"xexanoth\", \"ycnàgnnisssz\", \"yhoundeh\", \"aiueb gnshal\", \n",
    "    \"aletheia\", \"azhorra-tha\", \"c'thalpa\", \"daoloth\", \"ghroth\", \"gi-hoveg\", \"haiogh-yai\", \"huitloxopetl\", \"ialdagorth\", \n",
    "    \"kaajh'kaalbh\", \"kaalut\", \"lu-kthu\", \"mh'ithrha\", \"mlandoth\", \"mril thorion\", \"mother of pus\", \"nhimbaloth\", \n",
    "    \"ngyr-khorath\", \"nyctelios\", \"olkoth\", \"ramasekva\", \"shabbith-ka\", \"star mother\", \"suc'naath\", \"uvhash\", \"xa'ligha\", \n",
    "    \"yibb-tstll\", \"yidhra\", \"yomag'n'tho\"\n",
    "]\n",
    "\n",
    "# Function to extract entities\n",
    "def extract_entities(text):\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Initialize the list to store extracted entities\n",
    "    entities = []\n",
    "    \n",
    "    # Extract the named entities using spaCy's NER (PERSON, ORG, GPE, LOC)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in ['PERSON', 'ORG', 'GPE', 'LOC']:\n",
    "            entities.append(ent.text.lower())\n",
    "    \n",
    "    # Manually add expanded entities and regex pattern matches for indirect references\n",
    "    for entity in lovecraft_entities_expanded:\n",
    "        # Check for direct entity mentions (singular and plural)\n",
    "        singular_entity = r'\\b' + re.escape(entity) + r'\\b'\n",
    "        plural_entity = r'\\b' + re.escape(entity + \"s\") + r'\\b'  # Handle plural form\n",
    "\n",
    "        if re.search(singular_entity, text.lower()) or re.search(plural_entity, text.lower()):\n",
    "            entities.append(entity)\n",
    "        \n",
    "        # Check for indirect references or variations (e.g., \"great old ones\" or \"eldritch horror\")\n",
    "        indirect_references = [\n",
    "            r\"\\bdeep ones\\b\", r\"\\bcosmic entity\\b\", r\"\\bhorrible being\\b\", r\"\\bnight gaunts\\b\", r\"\\bblack stone\\b\",\n",
    "            r\"\\byog sothoth\\b\", r\"\\bnamesless city\\b\", r\"\\bstrange entity\\b\", r\"\\botherworldly creature\\b\", r\"\\bdark god\\b\",\n",
    "            r\"\\bhorrible power\\b\", r\"\\btimeless one\\b\"\n",
    "        ]\n",
    "        for pattern in indirect_references:\n",
    "            if re.search(pattern, text.lower()):\n",
    "                entities.append(entity)\n",
    "    \n",
    "    return entities\n",
    "\n",
    "# Apply the extraction to the 'Cleaned_Text' column (assuming 'Cleaned_Text' contains the content)\n",
    "df['Entities'] = df['Cleaned_Text'].apply(extract_entities)\n",
    "\n",
    "# Flatten the list of entities and get their frequency count\n",
    "all_entities = [entity for sublist in df['Entities'] for entity in sublist]\n",
    "entity_freq = Counter(all_entities)\n",
    "\n",
    "# Display the most common entities\n",
    "print(entity_freq.most_common(100))\n",
    "\n",
    "# Custom list of Lovecraft entities to track (including new entities)\n",
    "specific_entity_freq = {entity: all_entities.count(entity) for entity in lovecraft_entities_expanded}\n",
    "\n",
    "# Display the count of these specific entities\n",
    "print(specific_entity_freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Load the spaCy model for Named Entity Recognition\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Expanded list of Lovecraftian and related entities (including new ones)\n",
    "lovecraft_entities_expanded = [\n",
    "    \"cthulhu\", \"yog-sothoth\", \"nyarlathotep\", \"azathoth\", \"hastur\", \"r'lyeh\", \"dagon\", \n",
    "    \"shub-niggurath\", \"the great old ones\", \"elder gods\", \"the old ones\", \"the deep ones\", \"night gaunts\", \n",
    "    \"cthulhu cult\", \"the nameless city\", \"the black stone\", \"the dreamlands\", \"fenric\", \"hecuba\", \n",
    "    \"animus\", \"tor-gasukk\", \"moloch\", \"kai'lizakia\", \"lloigor\", \"eidolon\", \"derleth\", \"gog\", \"magog\", \"to'koth\", \n",
    "    \"karnas'koi\", \"traguam\", \"archon\", \"mi'en kalarash\", \"kwundaar\", \"volund\", \"k'thun\", \"noth-yidik\", \"tru'nembra\", \n",
    "    \"tulzscha\", \"cxaxukluth\", \"d'endrrah\", \"ubbo-sathla\", \"xexanoth\", \"ycnàgnnisssz\", \"yhoundeh\", \"aiueb gnshal\", \n",
    "    \"aletheia\", \"azhorra-tha\", \"c'thalpa\", \"daoloth\", \"ghroth\", \"gi-hoveg\", \"haiogh-yai\", \"huitloxopetl\", \"ialdagorth\", \n",
    "    \"kaajh'kaalbh\", \"kaalut\", \"lu-kthu\", \"mh'ithrha\", \"mlandoth\", \"mril thorion\", \"mother of pus\", \"nhimbaloth\", \n",
    "    \"ngyr-khorath\", \"nyctelios\", \"olkoth\", \"ramasekva\", \"shabbith-ka\", \"star mother\", \"suc'naath\", \"uvhash\", \"xa'ligha\", \n",
    "    \"yibb-tstll\", \"yidhra\", \"yomag'n'tho\"\n",
    "]\n",
    "\n",
    "# Function to extract entities\n",
    "def extract_entities(text):\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Initialize the list to store extracted entities\n",
    "    entities = []\n",
    "    \n",
    "    # Manually add expanded entities and regex pattern matches for direct references\n",
    "    for entity in lovecraft_entities_expanded:\n",
    "        # Check for direct entity mentions (singular and plural)\n",
    "        singular_entity = r'\\b' + re.escape(entity) + r'\\b'\n",
    "        plural_entity = r'\\b' + re.escape(entity + \"s\") + r'\\b'  # Handle plural form\n",
    "\n",
    "        if re.search(singular_entity, text.lower()) or re.search(plural_entity, text.lower()):\n",
    "            entities.append(entity)\n",
    "        \n",
    "        # Check for indirect references or variations (e.g., \"great old ones\" or \"eldritch horror\")\n",
    "        indirect_references = [\n",
    "            r\"\\bdeep ones\\b\", r\"\\bcosmic entity\\b\", r\"\\bhorrible being\\b\", r\"\\bnight gaunts\\b\", r\"\\bblack stone\\b\",\n",
    "            r\"\\byog sothoth\\b\", r\"\\bnamesless city\\b\", r\"\\bstrange entity\\b\", r\"\\botherworldly creature\\b\", r\"\\bdark god\\b\",\n",
    "            r\"\\bhorrible power\\b\", r\"\\btimeless one\\b\"\n",
    "        ]\n",
    "        for pattern in indirect_references:\n",
    "            if re.search(pattern, text.lower()):\n",
    "                entities.append(entity)\n",
    "    \n",
    "    return entities\n",
    "\n",
    "# Apply the extraction to the 'Cleaned_Text' column (assuming 'Cleaned_Text' contains the content)\n",
    "df['Entities'] = df['Cleaned_Text'].apply(extract_entities)\n",
    "\n",
    "# Flatten the list of entities and get their frequency count\n",
    "all_entities = [entity for sublist in df['Entities'] for entity in sublist]\n",
    "entity_freq = Counter(all_entities)\n",
    "\n",
    "# Display the most common entities\n",
    "print(entity_freq.most_common(100))\n",
    "\n",
    "# Custom list of Lovecraft entities to track (including new entities)\n",
    "specific_entity_freq = {entity: all_entities.count(entity) for entity in lovecraft_entities_expanded}\n",
    "\n",
    "# Display the count of these specific entities\n",
    "print(specific_entity_freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Humanoid Names ---\n",
      "carter: 175\n",
      "willett: 99\n",
      "joseph curwen: 53\n",
      "johnny: 20\n",
      "ammi: 19\n",
      "denis: 19\n",
      "wilbur: 14\n",
      "ben: 14\n",
      "dobson: 14\n",
      "george campbell: 12\n",
      "fed: 12\n",
      "van der: 12\n",
      "steve: 11\n",
      "dalton: 11\n",
      "joe slater: 10\n",
      "nahum: 10\n",
      "davis: 10\n",
      "wilbur whateley: 10\n",
      "warren: 8\n",
      "joe mazurewicz: 8\n",
      "john: 8\n",
      "nova: 8\n",
      "romero: 8\n",
      "robert grandison: 8\n",
      "joe: 7\n",
      "arthur jermyn: 7\n",
      "jermyn house: 7\n",
      "robert suydam: 6\n",
      "anderson: 6\n",
      "james dalton: 6\n",
      "arthur munroe: 6\n",
      "herbert west: 5\n",
      "sefton: 5\n",
      "matt: 5\n",
      "miller: 5\n",
      "arthur wheeler: 5\n",
      "robert: 5\n",
      "henry akeley: 5\n",
      "norman: 5\n",
      "--- Cthulhu Mythos ---\n",
      "nyarlathotep: 42\n",
      "cthulhu: 22\n",
      "great cthulhu: 18\n",
      "azathoth: 18\n",
      "dagon: 17\n",
      "yog-sothoth: 13\n",
      "shub-niggurath: 13\n",
      "--- Locations & Settings ---\n",
      "arkham: 74\n",
      "miskatonic: 27\n",
      "innsmouth: 18\n",
      "dunwich: 14\n",
      "the nameless city: 13\n",
      "the dreamlands: 13\n",
      "r'lyeh: 13\n",
      "--- Cosmic Entities ---\n",
      "elder gods: 17\n",
      "colour out of space: 13\n",
      "the great old ones: 13\n",
      "the old ones: 13\n",
      "the deep ones: 13\n",
      "night gaunts: 13\n",
      "yog sothoth: 13\n",
      "--- Occult Entities ---\n",
      "moloch: 14\n",
      "archon: 14\n",
      "the great intelligence: 13\n",
      "guardians of time: 13\n",
      "hecuba: 13\n",
      "animus: 13\n",
      "toymakers: 13\n",
      "--- Mythos-Related Concepts ---\n",
      "boston: 51\n",
      "whateley: 45\n",
      "clarendon: 35\n",
      "london: 33\n",
      "new york: 32\n",
      "africa: 26\n",
      "vermont: 21\n",
      "egypt: 20\n",
      "paris: 19\n",
      "eidolon: 18\n",
      "europe: 17\n",
      "mummy: 17\n",
      "san francisco: 16\n",
      "washington: 16\n",
      "thou: 16\n",
      "wolf: 15\n",
      "cthulhu cult: 15\n",
      "hastur: 14\n",
      "dunwich horror: 14\n",
      "derleth: 14\n",
      "cairo: 14\n",
      "grey: 14\n",
      "the king in yellow: 13\n",
      "the dark young: 13\n",
      "the black stone: 13\n",
      "the whisperer in darkness: 13\n",
      "the colour out of space: 13\n",
      "the shadow over innsmouth: 13\n",
      "fenric: 13\n",
      "nestene consciousness: 13\n",
      "celestial toymaker: 13\n",
      "gods of ragnarok: 13\n",
      "tor-gasukk: 13\n",
      "kai'lizakia: 13\n",
      "lloigor: 13\n",
      "gog and magog: 13\n",
      "to'koth: 13\n",
      "karnas'koi: 13\n",
      "traguam: 13\n",
      "mi'en kalarash: 13\n",
      "kwundaar: 13\n",
      "volund: 13\n",
      "k'thun: 13\n",
      "the nameless mist: 13\n",
      "noth-yidik: 13\n",
      "tru'nembra: 13\n",
      "tulzscha: 13\n",
      "abhoth: 13\n",
      "cxaxukluth: 13\n",
      "d'endrrah: 13\n",
      "ubbo-sathla: 13\n",
      "xexanoth: 13\n",
      "ycnàgnnisssz: 13\n",
      "yhoundeh: 13\n",
      "aiueb gnshal: 13\n",
      "aletheia: 13\n",
      "azhorra-tha: 13\n",
      "the blackness from the stars: 13\n",
      "the cloud-thing: 13\n",
      "c'thalpa: 13\n",
      "daoloth: 13\n",
      "ghroth: 13\n",
      "gi-hoveg: 13\n",
      "haiogh-yai: 13\n",
      "huitloxopetl: 13\n",
      "ialdagorth: 13\n",
      "kaajh'kaalbh: 13\n",
      "kaalut: 13\n",
      "lu-kthu: 13\n",
      "mh'ithrha: 13\n",
      "mlandoth: 13\n",
      "mril thorion: 13\n",
      "mother of pus: 13\n",
      "nhimbaloth: 13\n",
      "ngyr-khorath: 13\n",
      "nyctelios: 13\n",
      "olkoth: 13\n",
      "ramasekva: 13\n",
      "shabbith-ka: 13\n",
      "star mother: 13\n",
      "suc'naath: 13\n",
      "uvhash: 13\n",
      "xa'ligha: 13\n",
      "yibb-tstll: 13\n",
      "yidhra: 13\n",
      "yomagn'tho: 13\n",
      "california: 13\n",
      "mexico city: 13\n",
      "france: 11\n",
      "us: 11\n",
      "new orleans: 11\n",
      "john brown: 11\n",
      "randolph carter: 11\n",
      "america: 10\n",
      "moon: 10\n",
      "mexico: 10\n",
      "de marigny: 10\n",
      "rome: 9\n",
      "gulf: 9\n",
      "house olney court: 9\n",
      "ezra weeden: 9\n",
      "spain: 9\n",
      "zoogs: 9\n",
      "san quentin: 9\n",
      "china: 9\n",
      "kodak: 9\n",
      "williams: 8\n",
      "titan: 8\n",
      "crest: 8\n",
      "florida: 8\n",
      "vista: 7\n",
      "galley: 7\n",
      "massachusetts: 7\n",
      "virginia: 7\n",
      "nile: 7\n",
      "van keulen: 7\n",
      "india: 6\n",
      "rhode island: 6\n",
      "arkansas: 6\n",
      "pinnacle: 6\n",
      "keziah: 6\n",
      "sacramento: 6\n",
      "chicago: 6\n",
      "bell: 6\n",
      "sepulchre: 6\n",
      "appleton: 6\n",
      "ford: 6\n",
      "lincoln: 6\n",
      "van allister: 5\n",
      "prague: 5\n",
      "asia: 5\n",
      "louisiana: 5\n",
      "castro: 5\n",
      "johansen: 5\n",
      "olney court: 5\n",
      "joseph: 5\n",
      "charles ward: 5\n",
      "holland: 5\n",
      "atlantic: 5\n",
      "sun: 5\n",
      "claes van der: 5\n",
      "pickman: 5\n",
      "earl sawyer: 5\n",
      "martin beach: 5\n",
      "doc: 5\n",
      "colonies: 5\n",
      "southward: 5\n",
      "earth: 5\n",
      "new hampshire: 5\n",
      "harley warren: 5\n",
      "lieut klenze: 5\n"
     ]
    }
   ],
   "source": [
    "# List of entities with their mentions\n",
    "entities = [\n",
    "     ('carter', 175), ('willett', 99), ('arkham', 74), ('joseph curwen', 53),\n",
    "    ('boston', 51), ('whateley', 45), ('nyarlathotep', 42), ('clarendon', 35),\n",
    "    ('london', 33), ('new york', 32), ('miskatonic', 27), ('africa', 26),\n",
    "    ('cthulhu', 22), ('vermont', 21), ('egypt', 20), ('johnny', 20),\n",
    "    ('paris', 19), ('ammi', 19), ('denis', 19), ('great cthulhu', 18),\n",
    "    ('innsmouth', 18), ('azathoth', 18), ('eidolon', 18), ('europe', 17),\n",
    "    ('elder gods', 17), ('dagon', 17), ('mummy', 17), ('san francisco', 16),\n",
    "    ('washington', 16), ('thou', 16), ('wolf', 15), ('cthulhu cult', 15),\n",
    "    ('dunwich', 14), ('hastur', 14), ('dunwich horror', 14), ('moloch', 14),\n",
    "    ('derleth', 14), ('archon', 14), ('cairo', 14), ('grey', 14), ('wilbur', 14),\n",
    "    ('ben', 14), ('dobson', 14), ('yog-sothoth', 13), ('shub-niggurath', 13),\n",
    "    ('the king in yellow', 13), ('the dark young', 13), ('colour out of space', 13),\n",
    "    ('the great old ones', 13), ('the old ones', 13), ('the deep ones', 13),\n",
    "    ('night gaunts', 13), ('the nameless city', 13), ('the black stone', 13),\n",
    "    ('the dreamlands', 13), (\"r'lyeh\", 13), ('yog sothoth', 13),\n",
    "    ('the whisperer in darkness', 13), ('the colour out of space', 13),\n",
    "    ('the shadow over innsmouth', 13), ('the great intelligence', 13),\n",
    "    ('fenric', 13), ('nestene consciousness', 13), ('guardians of time', 13),\n",
    "    ('celestial toymaker', 13), ('gods of ragnarok', 13), ('hecuba', 13),\n",
    "    ('animus', 13), ('tor-gasukk', 13), (\"kai'lizakia\", 13), ('lloigor', 13),\n",
    "    ('toymakers', 13), ('gog and magog', 13), (\"to'koth\", 13), (\"karnas'koi\", 13),\n",
    "    ('traguam', 13), (\"mi'en kalarash\", 13), ('kwundaar', 13), ('volund', 13),\n",
    "    (\"k'thun\", 13), ('the nameless mist', 13), ('noth-yidik', 13), (\"tru'nembra\", 13),\n",
    "    ('tulzscha', 13), ('abhoth', 13), ('cxaxukluth', 13), (\"d'endrrah\", 13),\n",
    "    ('ubbo-sathla', 13), ('xexanoth', 13), ('ycnàgnnisssz', 13), ('yhoundeh', 13),\n",
    "    ('aiueb gnshal', 13), ('aletheia', 13), ('azhorra-tha', 13),\n",
    "    ('the blackness from the stars', 13), ('the cloud-thing', 13), (\"c'thalpa\", 13),\n",
    "    ('daoloth', 13), ('ghroth', 13), ('gi-hoveg', 13), ('haiogh-yai', 13),\n",
    "    ('huitloxopetl', 13), ('ialdagorth', 13), (\"kaajh'kaalbh\", 13), ('kaalut', 13),\n",
    "    ('lu-kthu', 13), (\"mh'ithrha\", 13), ('mlandoth', 13), ('mril thorion', 13),\n",
    "    ('mother of pus', 13), ('nhimbaloth', 13), ('ngyr-khorath', 13), ('nyctelios', 13),\n",
    "    ('olkoth', 13), ('ramasekva', 13), ('shabbith-ka', 13), ('star mother', 13),\n",
    "    (\"suc'naath\", 13), ('uvhash', 13), (\"xa'ligha\", 13), ('yibb-tstll', 13),\n",
    "    ('yidhra', 13), (\"yomagn'tho\", 13), ('california', 13), ('mexico city', 13),\n",
    "    ('george campbell', 12), ('fed', 12), ('van der', 12), ('france', 11),\n",
    "    ('us', 11), ('new orleans', 11), ('john brown', 11), ('randolph carter', 11),\n",
    "    ('steve', 11), ('dalton', 11), ('joe slater', 10), ('america', 10),\n",
    "    ('nahum', 10), ('moon', 10), ('davis', 10), ('wilbur whateley', 10),\n",
    "    ('mexico', 10), ('de marigny', 10), ('rome', 9), ('gulf', 9),\n",
    "    ('house olney court', 9), ('ezra weeden', 9), ('spain', 9), ('zoogs', 9),\n",
    "    ('san quentin', 9), ('china', 9), ('kodak', 9), ('williams', 8), ('warren', 8),\n",
    "    ('titan', 8), ('crest', 8), ('joe mazurewicz', 8), ('florida', 8),\n",
    "    ('john', 8), ('nova', 8), ('romero', 8), ('robert grandison', 8), ('vista', 7),\n",
    "    ('galley', 7), ('massachusetts', 7), ('joe', 7), ('arthur jermyn', 7),\n",
    "    ('jermyn house', 7), ('virginia', 7), ('nile', 7), ('van keulen', 7),\n",
    "    ('india', 6), ('rhode island', 6), ('arkansas', 6), ('pinnacle', 6),\n",
    "    ('keziah', 6), ('sacramento', 6), ('chicago', 6), ('bell', 6), ('robert suydam', 6),\n",
    "    ('sepulchre', 6), ('anderson', 6), ('james dalton', 6), ('arthur munroe', 6),\n",
    "    ('appleton', 6), ('ford', 6), ('lincoln', 6), ('van allister', 5),\n",
    "    ('prague', 5), ('asia', 5), ('louisiana', 5), ('castro', 5), ('johansen', 5),\n",
    "    ('olney court', 5), ('joseph', 5), ('charles ward', 5), ('holland', 5),\n",
    "    ('atlantic', 5), ('sun', 5), ('claes van der', 5), ('pickman', 5),\n",
    "    ('earl sawyer', 5), ('herbert west', 5), ('sefton', 5), ('martin beach', 5),\n",
    "    ('doc', 5), ('matt', 5), ('miller', 5), ('colonies', 5), ('southward', 5),\n",
    "    ('arthur wheeler', 5), ('earth', 5), ('new hampshire', 5), ('harley warren', 5),\n",
    "    ('lieut klenze', 5), ('robert', 5), ('henry akeley', 5), ('norman', 5)\n",
    "]\n",
    "\n",
    "# Function to filter and categorize entities\n",
    "def filter_lovecraft_entities(entities, exclude_humans=True):\n",
    "    # List of human names to be excluded\n",
    "    human_names = ['carter', 'willett', 'joseph curwen', 'johnny', 'ammi', 'denis', \n",
    "                   'wilbur', 'ben', 'dobson', 'george campbell', 'fed', 'van der', 'steve', \n",
    "                   'dalton', 'joe slater', 'nahum', 'davis', 'wilbur whateley', 'joe', \n",
    "                   'john', 'nova', 'romero', 'robert grandison', 'joe mazurewicz', 'warren', \n",
    "                   'joe', 'arthur jermyn', 'jermyn house', 'joe', 'arthur munroe', 'james dalton', \n",
    "                   'anderson', 'robert suydam', 'herbert west', 'sefton', 'matt', 'miller', \n",
    "                   'arthur wheeler', 'robert', 'henry akeley', 'norman']\n",
    "    \n",
    "    # Create a dictionary to store entities by category\n",
    "    categories = {\n",
    "        'Humanoid Names': [],\n",
    "        'Cthulhu Mythos': [],\n",
    "        'Locations & Settings': [],\n",
    "        'Cosmic Entities': [],\n",
    "        'Occult Entities': [],\n",
    "        'Mythos-Related Concepts': []\n",
    "    }\n",
    "    \n",
    "    # Process each entity in the list\n",
    "    for entity, mentions in entities:\n",
    "        # Exclude human characters\n",
    "        if exclude_humans and entity.lower() in human_names:\n",
    "            categories['Humanoid Names'].append((entity, mentions))\n",
    "            continue\n",
    "        \n",
    "        # Categorize entities based on their known groupings\n",
    "        if entity in ['cthulhu', 'great cthulhu', 'nyarlathotep', 'azathoth', 'shub-niggurath', 'dagon', 'yog-sothoth']:\n",
    "            categories['Cthulhu Mythos'].append((entity, mentions))\n",
    "        elif entity in ['arkham', 'miskatonic', 'innsmouth', 'dunwich', 'r\\'lyeh', 'the dreamlands', 'the nameless city']:\n",
    "            categories['Locations & Settings'].append((entity, mentions))\n",
    "        elif entity in ['elder gods', 'the old ones', 'the great old ones', 'night gaunts', 'the deep ones', 'colour out of space', 'yog sothoth']:\n",
    "            categories['Cosmic Entities'].append((entity, mentions))\n",
    "        elif entity in ['toymakers', 'guardians of time', 'the great intelligence', 'moloch', 'hecuba', 'animus', 'archon']:\n",
    "            categories['Occult Entities'].append((entity, mentions))\n",
    "        else:\n",
    "            categories['Mythos-Related Concepts'].append((entity, mentions))\n",
    "    \n",
    "    return categories\n",
    "\n",
    "# Apply the filter\n",
    "filtered_entities = filter_lovecraft_entities(entities)\n",
    "\n",
    "# Print the result\n",
    "for category, entities_list in filtered_entities.items():\n",
    "    print(f\"--- {category} ---\")\n",
    "    for entity, mentions in entities_list:\n",
    "        print(f\"{entity}: {mentions}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
